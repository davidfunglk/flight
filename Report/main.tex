%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% WikiBooks (http://en.wikibooks.org/wiki/LaTeX/Title_Creation)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\title{Title page with logo}
%--------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%-------------------------------------------------------------

\documentclass[12pt]{article}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
}
 
\urlstyle{same}

\usepackage{listings}
\usepackage{color}
 
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
 
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
 
\lstset{style=mystyle}

\usepackage{fancyhdr} % Required for custom headers
\usepackage{lastpage} % Required to determine the last page for the footer
\usepackage{extramarks} % Required for headers and footers
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template
\usepackage{bm}
\usepackage{float}
\usepackage{mathtools}
\usepackage{enumerate}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{subcaption}
\usepackage{caption}
\usepackage{graphicx}
\usepackage{enumerate}
\usepackage{multirow}

% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in 
\linespread{1.1} % Line spacing

% Set up the header and footer
\pagestyle{fancy}
\lhead{}
\chead{Analysis on the Effect of Atlantic Hurricanes on the US Airport Network} % Top center header
\rhead{\firstxmark} % Top right header
\lfoot{\lastxmark} % Bottom left footer
\cfoot{} % Bottom center footer
\rfoot{Page\ \thepage\ of\ \pageref{LastPage}} % Bottom right footer
\renewcommand\headrulewidth{0.4pt} % Size of the header rule
\renewcommand\footrulewidth{0.4pt} % Size of the footer rule

\setlength\parindent{0pt} % Removes all indentation from paragraphs


\begin{document}

\begin{titlepage}

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page
 
%--------------------------------------------------------------
%	HEADING SECTIONS
%--------------------------------------------------------------

\textsc{\LARGE University of California Davis }\\[0.3cm] 
\textsc{\Large Department of Statistics}\\[0.5cm] 
 % Minor heading such as course title

%--------------------------------------------------------------
%	TITLE SECTION
%--------------------------------------------------------------

\HRule \\[0.4cm]
{ \huge \bfseries Practice in Statistical Data Science\\  (STA-160)}\\[0.03cm]
\HRule \\[1.5cm]

\hfill \break \hfill \break \hfill \break
{ \huge \bfseries Analysis on the Effect of Atlantic Hurricanes on the US Airport Network}\\
\hfill \break \hfill \break \hfill \break
\hfill \break

{\large David Fung \\ Yu Chan\\ Jiahui Tan}\\
 
%--------------------------------------------------------------

\vfill % Fill the rest of the page with whitespace

\end{titlepage}

\newpage
\tableofcontents
\newpage
%--------------------------------------------------------------
%Project Start
%--------------------------------------------------------------
\section{Abstract} \label{sec:Abstract}

The airport system are characterized by a network structure connecting different operation centers. In this report, we study the performance and resilience of US airports reacting to the extreme weather condition of hurricanes, by measuring how delay and cancellation rate propagates throughout time when different Atlantic hurricanes hits the US coastals. We focused our study on hurricane Katrina, Sandy, and Ike, category three to five hurricanes that directly hits onto the US. Our result suggests that when one of the major hubs is paralyzed, the effect can propagate, magnify and eventually involve a significant part of the network. Also, hurricanes striking along the eastern borders of the US will result in more cancellations in the airport network than those hitting the southern central borders, this is because more major hubs are concentrated in the East Coast. We also quantify the level of network congestion and cancellation rate and attempted at a prediction model of cancellations using the flight performance data. The random forest model results suggest that wind speed, followed by nature and distance were most indicative of probability of flight cancellation. 

\section{Introduction} \label{sec:Intro}

\input{./TexFiles/intro.tex}

\section{Description of Data} \label{sec:Descript} 

\subsection{Data Preprocessing}
\input{./TexFiles/DataDescription.tex}

\subsection{Data Exploration}
\input{./TexFiles/DataExploration.tex}

\section{Model} \label{sec:Model}
\input{./TexFiles/Model.tex}


\section{Conclusion} \label{sec:Conclusion}
The data sets for U.S. domestic flights are extremely large. Combining with hurricane data, it was quite a challenge to manage, subset, and analyze our data effectively. In addition, it was difficult to design a model that took into account the vast number of variables and dependencies within our data. Overall, we can tell that hurricanes with a path in Northeastern United States will have a bigger effect on flights than a hurricane going through Southeastern United States. This makes sense as there are generally more flights heading to and taking off from the major hubs in the East Coast (such as New York City). With bigger hurricanes, we can also identify with high certainty whether a flight will be cancelled. Smaller hurricanes present a challenge since they rarely hit mainland U.S., and even when they do, they rarely affect the flights. Overall, we would need to further explore the data with spatial analysis to create a more accurate model.

\section{Bibliography} \label{sec:Bibliography}
\begin{enumerate}
\item \href{http://point.fungservices.com/flightanalysis}{Website with Animation and Interactive Plots}
\item 
\href{https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&DB_Short_Name=On-Time}{On-time Performance Data of Flights}
\item \href{https://www.ncdc.noaa.gov/ibtracs/index.php?name=wmo-data}{Hurricane Data}
\item 
\href{https://raw.githubusercontent.com/jpatokal/openflights/master/data/airports.dat}{Airport Location Information}
\item \href{https://www.nature.com/articles/srep01159}{System Delay Propagation in the US Airport Network}
\item
\href{http://www.reuters.com/article/us-jetblue-airways-cancellation-analysis-idUSKBN0N50BF20150414}{ JetBlue Earliest to Cancel during Storms, Fewer Refunds Result}
\item 
\href{http://www.people.fas.harvard.edu/~zhukov/spatial.html}{Applied Spatial Statistics in R}
\item \href{http://www.statisticssolutions.com/assumptions-of-logistic-regression/}{Assumptions of Logistic Regression}
\end{enumerate}

\section{Project Reflections} \label{sec:Reflections}
The biggest challenge we have for this project was actually identifying and clarifying the question we want to answer and why any of this matters. We spend basically 9 out of the 10 weeks changing and revising our project to try to make it meaningful. Even up to the last minute, changes are being made to the project and we are constantly fighting with the question 'why it matters and to who?'. So if we learn anything in these 10 weeks, it was how important it is to have a well-define project to work with. Since our project goals were so unclear, we weren't able to spent much on learning a new method, which was unfortunate. If we were to do a similar project in the future, we believe the goal should be to make sure everyone is on the same page with a well-define goal way early in the project so we can have as little revision as possible. Of course, working with real data and having to define a problem that is interesting not only to you but to stakeholders is a big challenge itself. 

\section{Code Appendix} \label{sec:Code Appendix} 
\begin{lstlisting}[language=R, caption=Data Merging in R]
read_data_from_BTS = function(datadir){
  data = read.csv(datadir, stringsAsFactors = FALSE)
  colWanted = c("Year","Quarter","Month","DayofMonth","DayOfWeek","FlightDate",
                "UniqueCarrier","TailNum", "Origin","OriginCityName","OriginState",
                "Dest","DestCityName","DestState","DepTime","CRSDepTime","DepDelay",
                "DepDelayMinutes","DepDel15","DepTimeBlk","TaxiOut","WheelsOff","WheelsOn",
                "TaxiIn","CRSArrTime","ArrTime","ArrDelay","ArrDelayMinutes","ArrDel15",
                "ArrTimeBlk","CRSElapsedTime","ActualElapsedTime","Distance","DistanceGroup","Cancelled","CancellationCode",
                "CarrierDelay","WeatherDelay","NASDelay","SecurityDelay","LateAircraftDelay","Diverted")
  data = data[,colWanted]
  
  #  data = data[data$Origin %in% allAirports & 
  #           data$Dest %in% allAirports,]
  data
}

#Merge GPS Location
getGpsLocation = function(data){
  airports = read.csv("/media/sf_Windows/FlightData/airports.dat",header = FALSE,
                      col.names = c("ID","Name","City","Country","IATA","ICAO",
                                    "Lat","Lon","Altitude","Timezone","DST","Tz","Type","Source"))
  USairports = airports[airports$Country == 'United States',c("IATA", "Lat","Lon","Timezone")]
  finaldf = merge(data, USairports, by.x = 'Origin', by.y = 'IATA', all.x = TRUE)
  names(finaldf)[names(finaldf) %in% c('Lat','Lon','Timezone')] = paste("Origin",c('Lat','Lon','Timezone'))
  finaldf = merge(finaldf, USairports, by.x = 'Dest', by.y = 'IATA', all.x = TRUE)
  names(finaldf)[names(finaldf) %in% c('Lat','Lon','Timezone')] = paste("Dest",c('Lat','Lon','Timezone'))
  # #Fix timezone. Convert UTC offset to US timezone.
  finaldf$`Dest Timezone` = factor(finaldf$`Dest Timezone`)
  levels(finaldf$`Dest Timezone`) = c("US/Hawaii","US/Eastern","US/Central","US/Mountain","US/Pacific","US/Alaska")
  finaldf$`Origin Timezone` = factor(finaldf$`Origin Timezone`)
  levels(finaldf$`Origin Timezone`) = c("US/Hawaii","US/Eastern","US/Central","US/Mountain","US/Pacific","US/Alaska")
  finaldf = finaldf[!is.na(finaldf$`Dest Timezone`) & !is.na(finaldf$`Origin Timezone`),]
  return(finaldf)
}

library(lubridate)
convertToUTC = function(row){
  row[2] = as.numeric(row[2])
  if(nchar(row[2]) == 3)
    row[2] = paste0("0",row[2])
  if(nchar(row[2]) == 2)
    row[2] = paste0("00",row[2])
  if(nchar(row[2]) == 1)
    row[2] = paste0("000",row[2])
  date = paste(row[1:2],collapse = " ")
  return(date)
}

getDistanceFromLatLonInKm = function (lat1,lon1,lat2,lon2) {
  R = 6371;
  dLat = deg2rad(lat2-lat1)
  dLon = deg2rad(lon2-lon1) 
  a = 
    sin(dLat/2) * sin(dLat/2) +
    cos(deg2rad(lat1)) * cos(deg2rad(lat2)) * 
    sin(dLon/2) *sin(dLon/2)
  
  c = 2 * atan2(sqrt(a), sqrt(1-a))
  d = R * c * 0.621371
  return(d)
}

deg2rad = function (deg) {
  return(deg * (pi/180))
}

#Input DataFile
processStorm = function(dataFile) {
  stormdf = read_data_from_BTS(dataFile)

  #Identify Lon and Lat as well as timezone.
  df= getGpsLocation(stormdf)

  df$DepDateTime = apply(df[,c("FlightDate","CRSDepTime")], 1,convertToUTC)

  cols =  paste0("UTC",c("Year", "Month","DayofMonth",
                       "DayOfWeek","DepHour","CRSDepTime"))
  df[cols] = NA

  for(timezone in c("US/Hawaii","US/Eastern","US/Central",
                                                  "US/Mountain","US/Pacific","US/Alaska")){
    date = strptime(df$DepDateTime[df$`Origin Timezone` == timezone], 
                  format="%Y-%m-%d %H%M", tz = timezone)
    date = with_tz(date, tzone = 'UTC')
    newdf = data.frame(Year = year(date),Month = month(date), Day = day(date),
             DayOfWeek = weekdays(date), Hour = hour(date), Time = strftime(date, format="%Y-%m-%d %H:%M:%S"))
    newdf$Time = as.character(newdf$Time)
    newdf$DayOfWeek =as.character(newdf$DayOfWeek)
    df[df$`Origin Timezone` == timezone,cols] = newdf
  }

  #Put time in blocks
  utcTimes = strptime(df$UTCCRSDepTime, format="%Y-%m-%d %H:%M:%S", tz = 'UTC')
  SixHourBlock = cut(utcTimes, breaks = "6 hour")
  df$DepSixHourBlock = SixHourBlock 
  return(df)
}
\end{lstlisting}
\begin{lstlisting}[language=R, caption=Animation Plot in R]
#Animation Plot
plot_geo(locationmode = "USA-states") %>%
  add_markers(
    data = cancel_rate_ike_hubs, x = ~Lon, y = ~Lat, text = ~Name, frame = ~Group.2,
    hoverinfo = "text", alpha = 0.5, color = ~x, colors = c("green","yellow","orange","red","maroon")
  ) %>% 
  add_markers(
    data = points_ike, x = ~LON, y = ~LAT, frame = ~ISO_time, alpha = 0.3, size = ~INTENSITY, 
    color = ~'cancellation rate'
  ) %>%
  layout(
    title = paste("Ike and Airports' Cancellation Rate"), geo = geo, showlegend = FALSE
  ) %>%
  animation_opts(500, easing = "elastic",redraw = T
  ) %>%
  animation_slider(
    currentvalue = list(prefix = "Time Block ", font = list(color="Black"))
  )
 
#Clustering
cluster = sapply(1:19,function(i){
  routes[[i]]$Origin = factor(routes[[i]]$Origin)
  routes[[i]]$Dest = factor(routes[[i]]$Dest)
  airports = data.frame(name = delay_airport[[i]]$Group.1,congested = delay_airport[[i]]$congested)
  paths = data.frame(from = routes[[i]]$Origin, to = routes[[i]]$Dest)
  paths = paths[which(paths[,2] %in% airports$name),]
  paths = paths[which(paths[,1] %in% airports$name),]
  g = graph_from_data_frame(paths,vertices = airports)
  V(g)$color = ifelse(airports$congested == 1,"red","green")
  g = induced.subgraph(g,V(g)[V(g)$color %in% c("red")])
  plot(g)
  max(clusters(g)$csize)
})
 
p = ggplot(data = data15,aes(x = unique.cancel_rate_15.Group.2., y = cluster_15)) + 
    geom_bar(stat = "identity") + ggtitle("The Maximum of Cluster Size at Different Time of OCT 15") +
    xlab("Time") + ylab("Cluster Size") + theme(axis.text.x = element_text(angle = 90, hjust = 1))
p
\end{lstlisting}
\begin{lstlisting}[language=R, caption=Random Forest in R] 
#Modeling
extractFeatures = function(data){
  features = c("UniqueCarrier",
               "DepDistanceToStorm",
               "ArrDistanceToStorm",
               "UTCDayofMonth",
               "UTCDepHour",
               "Nature",
               "Wind.WMO.",
               "Pres.WMO.")
  fea = data[,features]
  fea$UniqueCarrier = as.factor(fea$UniqueCarrier)
  fea$Nature = as.factor(fea$Nature)
  return(fea)
}
set.seed(123)
modrf = randomForest(extractFeatures(train),as.factor(train$Cancelled),ntree = 1000,importance = T)
test$predict = predict(modrf,extractFeatures(test))
\end{lstlisting}
\begin{lstlisting}[language=R, caption= Sample Code forBubble Plots in R] 
p1 <- plot_ly(result[result$Name == "KATRINA",], x = ~averageDistanceToStorm, y = ~cancelledProp, 
              type = 'scatter', mode = 'markers', size = ~averageDepDelay , color = ~DayofMonthLabel,
              sizes = c(10, 50),
              marker = list(opacity = 0.3, sizemode = 'diameter'),
              colors= "RdYlBu",
              hoverinfo = 'text',
              text = ~paste('Airport:', ORIGIN,
                            '<br> Day of Month:', DayofMonth,
                            '<br>%of Cancelled Flights:', cancelledProp,
                            '<br>Flights Scheduled for Airport:', proportionFlights,
                            '<br>Average Departure Delay:', averageDepDelay))  %>% 
  layout(title = 'Hurricane Katrina')
\end{lstlisting}
\lstlistoflistings
\end{document}